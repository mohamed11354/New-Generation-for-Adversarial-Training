{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724e397a",
   "metadata": {},
   "source": [
    "# Kaggle notebook for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5096f7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-23T19:13:37.516988Z",
     "iopub.status.busy": "2024-09-23T19:13:37.516637Z",
     "iopub.status.idle": "2024-09-23T19:13:50.734869Z",
     "shell.execute_reply": "2024-09-23T19:13:50.734066Z"
    },
    "papermill": {
     "duration": 13.227741,
     "end_time": "2024-09-23T19:13:50.737257",
     "exception": false,
     "start_time": "2024-09-23T19:13:37.509516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 19:13:39.345436: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-23 19:13:39.345566: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-23 19:13:39.482270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from tensorflow.keras.callbacks import  EarlyStopping\n",
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, BatchNormalization, Dropout, Input, Activation, Add, Dense, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53a453a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T19:13:50.749402Z",
     "iopub.status.busy": "2024-09-23T19:13:50.748847Z",
     "iopub.status.idle": "2024-09-23T19:13:51.449372Z",
     "shell.execute_reply": "2024-09-23T19:13:51.448501Z"
    },
    "papermill": {
     "duration": 0.708795,
     "end_time": "2024-09-23T19:13:51.451598",
     "exception": false,
     "start_time": "2024-09-23T19:13:50.742803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c0b0be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T19:13:51.463811Z",
     "iopub.status.busy": "2024-09-23T19:13:51.463266Z",
     "iopub.status.idle": "2024-09-23T19:13:58.643698Z",
     "shell.execute_reply": "2024-09-23T19:13:58.642920Z"
    },
    "papermill": {
     "duration": 7.18894,
     "end_time": "2024-09-23T19:13:58.646042",
     "exception": false,
     "start_time": "2024-09-23T19:13:51.457102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "mean_cifar = np.mean(X_train/255.,axis = (0,1,2))\n",
    "std_cifar = np.std(X_train/255.,axis = (0,1,2))\n",
    "\n",
    "res = tf.keras.layers.Rescaling(1/255)\n",
    "norm = tf.keras.layers.Normalization(mean=mean_cifar, variance=std_cifar**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac16e80",
   "metadata": {},
   "source": [
    "# IG adversarial training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c9e06aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T19:13:58.697614Z",
     "iopub.status.busy": "2024-09-23T19:13:58.697307Z",
     "iopub.status.idle": "2024-09-23T19:13:58.718811Z",
     "shell.execute_reply": "2024-09-23T19:13:58.718062Z"
    },
    "papermill": {
     "duration": 0.035033,
     "end_time": "2024-09-23T19:13:58.720661",
     "exception": false,
     "start_time": "2024-09-23T19:13:58.685628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker = tf.keras.metrics.SparseCategoricalCrossentropy(name=\"loss\")\n",
    "#         self.mae_metric = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "        self.sparscat_metric=tf.keras.metrics.SparseCategoricalAccuracy(name='sparse_categorical_accuracy')\n",
    " #       self.delta = tf.Variable(tf.zeros([32,224,224,3]))\n",
    "    \n",
    "\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to fit().\n",
    "        x, y = data\n",
    "        y = tf.cast(y,tf.int32)\n",
    "        x = tf.cast(x,tf.float32)\n",
    "        eps=8.0\n",
    "        m = 4\n",
    "        alpha = eps/m\n",
    "        g_adv = tf.zeros_like(x)\n",
    "        for i in range(m):\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(x)\n",
    "                predictions = self(x, training = True) \n",
    "                loss = self.compute_loss(y=y,y_pred=predictions)\n",
    "            delta_mig = self.IG(x,y)\n",
    "            g_adv = g_adv + (delta_mig/tf.norm(delta_mig,1))\n",
    "            grad = tape.gradient(loss, self.trainable_variables)\n",
    "            x = x - alpha*tf.sign(g_adv) # (+) overfit (-) regularization\n",
    "            x = tf.clip_by_value(x, x-eps, x+eps)\n",
    "        \n",
    "\n",
    "            self.optimizer.apply_gradients(zip(grad, self.trainable_variables))\n",
    "\n",
    "            for metric in self.metrics:\n",
    "                metric.update_state(y, predictions)\n",
    "            # Return a dict mapping metric names to current value\n",
    "            result= {m.name: m.result() for m in self.metrics}\n",
    "         \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def IG(self, images, labels):\n",
    "        # interpolated intensities\n",
    "        alphas_x = tf.linspace(0.0,1.0,16)\n",
    "\n",
    "        # standardize input\n",
    "        #images = tf.cast(images,'float32')\n",
    "        labels = tf.squeeze(labels)\n",
    "        #labels = tf.cast(labels,tf.int32)\n",
    "\n",
    "        # calculate interpolated images\n",
    "        delta = tf.expand_dims(images,1)\n",
    "        interpolated = delta * alphas_x\n",
    "\n",
    "        # calculate gradient for each image\n",
    "        grads = tf.TensorArray(tf.float32,400)\n",
    "        #grads = []\n",
    "        i = 0\n",
    "        #print(labels.dtype)\n",
    "        for inter in interpolated:\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(inter)\n",
    "                probs = self(inter)[:,labels[i]]\n",
    "            grads = grads.write(i,tape.gradient(probs,inter))\n",
    "            #grads.append(tape.gradient(probs,inter))\n",
    "            i+= 1\n",
    "\n",
    "        grads = grads.stack()\n",
    "        #grads = tf.convert_to_tensor(grads, dtype=tf.float32)\n",
    "        # aproximate integration using remain trapoziod\n",
    "        grads = (grads[:,:-1] + grads[:,1:]) / tf.constant(2.0)\n",
    "        avg_gradients = tf.math.reduce_mean(grads, axis=1)\n",
    "\n",
    "        integrated_gradient = images * avg_gradients\n",
    "\n",
    "        return integrated_gradient\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our Metric objects here so that reset_states() can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of evaluate().\n",
    "        return [ self.loss_tracker,self.sparscat_metric]\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        # Compute predictions\n",
    "        y_pred = self(x, training=False)\n",
    "        # Updates the metrics tracking the loss\n",
    "        self.compute_loss(y=y, y_pred=y_pred)\n",
    "        # Update the metrics.\n",
    "        for metric in self.metrics:\n",
    "                metric.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbb490",
   "metadata": {},
   "source": [
    "# WideResNet Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f6d849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T19:13:58.743949Z",
     "iopub.status.busy": "2024-09-23T19:13:58.743618Z",
     "iopub.status.idle": "2024-09-23T19:13:58.765307Z",
     "shell.execute_reply": "2024-09-23T19:13:58.764332Z"
    },
    "papermill": {
     "duration": 0.035903,
     "end_time": "2024-09-23T19:13:58.767309",
     "exception": false,
     "start_time": "2024-09-23T19:13:58.731406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "if K.image_data_format() == \"th\":\n",
    "    channel_axis = 1\n",
    "    input_shape = (3, image_size, image_size)\n",
    "else:\n",
    "    channel_axis = -1\n",
    "    input_shape = (image_size, image_size, 3)\n",
    "\n",
    "def _wide_basic(n_input_plane, n_output_plane, stride, weight_decay = 0.0005,\n",
    "                dropout_probability = 0, weight_init = \"random_uniform\", use_bias = False):\n",
    "    def f(net):\n",
    "        # format of conv_params:\n",
    "        #               [ [nb_col=\"kernel width\", nb_row=\"kernel height\",\n",
    "        #               subsample=\"(stride_vertical,stride_horizontal)\",\n",
    "        #               border_mode=\"same\" or \"valid\"] ]\n",
    "        # B(3,3): orignal <<basic>> block\n",
    "        conv_params = [ [3,3,stride,\"same\"],\n",
    "                        [3,3,(1,1),\"same\"] ]\n",
    "        \n",
    "        n_bottleneck_plane = n_output_plane\n",
    "\n",
    "        # Residual block\n",
    "        for i, v in enumerate(conv_params):\n",
    "            if i == 0:\n",
    "                if n_input_plane != n_output_plane:\n",
    "                    net = BatchNormalization(axis=channel_axis)(net)\n",
    "                    net = Activation(\"relu\")(net)\n",
    "                    convs = net\n",
    "                else:\n",
    "                    convs = BatchNormalization(axis=channel_axis)(net)\n",
    "                    convs = Activation(\"relu\")(convs)\n",
    "                convs = Conv2D(n_bottleneck_plane, \n",
    "                               (v[0],v[1]),\n",
    "                                strides=v[2],\n",
    "                                padding=v[3],\n",
    "                                kernel_initializer=weight_init,\n",
    "                                kernel_regularizer=l2(weight_decay),\n",
    "                                use_bias=use_bias)(convs)\n",
    "            else:\n",
    "                convs = BatchNormalization(axis=channel_axis)(convs)\n",
    "                convs = Activation(\"relu\")(convs)\n",
    "                if dropout_probability > 0:\n",
    "                    convs = Dropout(dropout_probability)(convs)\n",
    "                convs = Conv2D(n_bottleneck_plane, \n",
    "                               (v[0],v[1]),\n",
    "                                strides=v[2],\n",
    "                                padding=v[3],\n",
    "                                kernel_initializer=weight_init,\n",
    "                                kernel_regularizer=l2(weight_decay),\n",
    "                                use_bias=use_bias)(convs)\n",
    "\n",
    "        # Shortcut Conntection: identity function or 1x1 convolutional\n",
    "        #  (depends on difference between input & output shape - this\n",
    "        #   corresponds to whether we are using the first block in each\n",
    "        #   group; see _layer() ).\n",
    "        if n_input_plane != n_output_plane:\n",
    "            shortcut = Conv2D(n_output_plane, \n",
    "                              (1,1),\n",
    "                              strides=stride,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=weight_init,\n",
    "                              kernel_regularizer=l2(weight_decay),\n",
    "                              use_bias=use_bias)(net)\n",
    "        else:\n",
    "            shortcut = net\n",
    "\n",
    "        return Add()([convs, shortcut])\n",
    "    \n",
    "    return f\n",
    "\n",
    "# \"Stacking Residual Units on the same stage\"\n",
    "def _layer(block, n_input_plane, n_output_plane, count, stride):\n",
    "    def f(net):\n",
    "        net = block(n_input_plane, n_output_plane, stride)(net)\n",
    "        for i in range(2,int(count+1)):\n",
    "            net = block(n_output_plane, n_output_plane, stride=(1,1))(net)\n",
    "        return net\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "def WideResNet(depth, width, input_shape, nb_classes, weight_decay = 0.0005,\n",
    "                  dropout_probability = 0, weight_init = \"random_uniform\", use_bias = False):\n",
    "    assert((depth - 4) % 6 == 0)\n",
    "    n = (depth - 4) / 6\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    n_stages=[16, 16*width, 32*width, 64*width]\n",
    "\n",
    "\n",
    "    conv1 = Conv2D(n_stages[0], \n",
    "                    (3, 3), \n",
    "                    strides=1,\n",
    "                    padding=\"same\",\n",
    "                    kernel_initializer=weight_init,\n",
    "                    kernel_regularizer=l2(weight_decay),\n",
    "                    use_bias=use_bias)(inputs) # \"One conv at the beginning (spatial size: 32x32)\"\n",
    "\n",
    "    # Add wide residual blocks\n",
    "    block_fn = _wide_basic\n",
    "    conv2 = _layer(block_fn, n_input_plane=n_stages[0], n_output_plane=n_stages[1], count=n, stride=(1,1))(conv1)# \"Stage 1 (spatial size: 32x32)\"\n",
    "    conv3 = _layer(block_fn, n_input_plane=n_stages[1], n_output_plane=n_stages[2], count=n, stride=(2,2))(conv2)# \"Stage 2 (spatial size: 16x16)\"\n",
    "    conv4 = _layer(block_fn, n_input_plane=n_stages[2], n_output_plane=n_stages[3], count=n, stride=(2,2))(conv3)# \"Stage 3 (spatial size: 8x8)\"\n",
    "\n",
    "    batch_norm = BatchNormalization(axis=channel_axis)(conv4)\n",
    "    relu = Activation(\"relu\")(batch_norm)\n",
    "                                            \n",
    "    # Classifier block\n",
    "    pool = AveragePooling2D(pool_size=(8, 8), strides=(1, 1), padding=\"same\")(relu)\n",
    "    flatten = Flatten()(pool)\n",
    "    predictions = Dense(units=nb_classes, kernel_initializer=weight_init, use_bias=use_bias,\n",
    "                        kernel_regularizer=l2(weight_decay), activation=\"softmax\")(flatten)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "549e1ba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T19:13:58.789949Z",
     "iopub.status.busy": "2024-09-23T19:13:58.789617Z",
     "iopub.status.idle": "2024-09-23T19:13:59.484137Z",
     "shell.execute_reply": "2024-09-23T19:13:59.483285Z"
    },
    "papermill": {
     "duration": 0.70843,
     "end_time": "2024-09-23T19:13:59.486531",
     "exception": false,
     "start_time": "2024-09-23T19:13:58.778101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lr_schedule = [30, 50, 70] # epoch_step\n",
    "lr_schedule = [5, 15, 22] # epoch_step\n",
    "def schedule(epoch_idx):\n",
    "    return 0.001 - epoch_idx * 0.0000396 # linear schedule\n",
    "\n",
    "with strategy.scope():\n",
    "    inputs = tf.keras.layers.Input((32, 32, 3))\n",
    "    r = res(inputs)\n",
    "    pre = norm(r)\n",
    "    model = WideResNet(40,2, input_shape, 10)\n",
    "    outputs = model(pre)\n",
    "    WRN = CustomModel(inputs = inputs, outputs = outputs)\n",
    "    WRN.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.01,weight_decay=1e-3),loss = \"sparse_categorical_crossentropy\",metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f5032c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T19:13:59.510441Z",
     "iopub.status.busy": "2024-09-23T19:13:59.510113Z",
     "iopub.status.idle": "2024-09-24T05:54:39.483178Z",
     "shell.execute_reply": "2024-09-24T05:54:39.482139Z"
    },
    "papermill": {
     "duration": 38439.987217,
     "end_time": "2024-09-24T05:54:39.485774",
     "exception": false,
     "start_time": "2024-09-23T19:13:59.498557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1629s\u001b[0m 12s/step - loss: 1.8303 - sparse_categorical_accuracy: 0.3420 - val_loss: 1.6187 - val_sparse_categorical_accuracy: 0.4207 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 1.5285 - sparse_categorical_accuracy: 0.4319 - val_loss: 1.4637 - val_sparse_categorical_accuracy: 0.4793 - learning_rate: 9.6040e-04\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 1.4186 - sparse_categorical_accuracy: 0.4754 - val_loss: 1.1852 - val_sparse_categorical_accuracy: 0.5919 - learning_rate: 9.2080e-04\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 1.3060 - sparse_categorical_accuracy: 0.5201 - val_loss: 1.0483 - val_sparse_categorical_accuracy: 0.6307 - learning_rate: 8.8120e-04\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 1.2266 - sparse_categorical_accuracy: 0.5514 - val_loss: 1.5575 - val_sparse_categorical_accuracy: 0.4988 - learning_rate: 8.4160e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 1.1566 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.9829 - val_sparse_categorical_accuracy: 0.6693 - learning_rate: 8.0200e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 1.1101 - sparse_categorical_accuracy: 0.5961 - val_loss: 0.9080 - val_sparse_categorical_accuracy: 0.7010 - learning_rate: 7.6240e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 1.0769 - sparse_categorical_accuracy: 0.6103 - val_loss: 1.0029 - val_sparse_categorical_accuracy: 0.6536 - learning_rate: 7.2280e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 1.0208 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.8606 - val_sparse_categorical_accuracy: 0.7024 - learning_rate: 6.8320e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 0.9946 - sparse_categorical_accuracy: 0.6396 - val_loss: 0.8284 - val_sparse_categorical_accuracy: 0.7246 - learning_rate: 6.4360e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 0.9592 - sparse_categorical_accuracy: 0.6510 - val_loss: 0.7893 - val_sparse_categorical_accuracy: 0.7348 - learning_rate: 6.0400e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 0.9105 - sparse_categorical_accuracy: 0.6703 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.7627 - learning_rate: 5.6440e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 0.8926 - sparse_categorical_accuracy: 0.6748 - val_loss: 0.7133 - val_sparse_categorical_accuracy: 0.7710 - learning_rate: 5.2480e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1538s\u001b[0m 12s/step - loss: 0.8477 - sparse_categorical_accuracy: 0.6946 - val_loss: 0.6320 - val_sparse_categorical_accuracy: 0.7888 - learning_rate: 4.8520e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 0.8215 - sparse_categorical_accuracy: 0.7016 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.7800 - learning_rate: 4.4560e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 0.7780 - sparse_categorical_accuracy: 0.7160 - val_loss: 0.7928 - val_sparse_categorical_accuracy: 0.7226 - learning_rate: 4.0600e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 0.7363 - sparse_categorical_accuracy: 0.7302 - val_loss: 0.6126 - val_sparse_categorical_accuracy: 0.7872 - learning_rate: 3.6640e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 0.7135 - sparse_categorical_accuracy: 0.7395 - val_loss: 0.6107 - val_sparse_categorical_accuracy: 0.8013 - learning_rate: 3.2680e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 0.6645 - sparse_categorical_accuracy: 0.7577 - val_loss: 0.5470 - val_sparse_categorical_accuracy: 0.8184 - learning_rate: 2.8720e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 12s/step - loss: 0.6216 - sparse_categorical_accuracy: 0.7722 - val_loss: 0.5226 - val_sparse_categorical_accuracy: 0.8257 - learning_rate: 2.4760e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1522s\u001b[0m 12s/step - loss: 0.5666 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5666 - val_sparse_categorical_accuracy: 0.8057 - learning_rate: 2.0800e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 12s/step - loss: 0.5168 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.5747 - val_sparse_categorical_accuracy: 0.8093 - learning_rate: 1.6840e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 12s/step - loss: 0.4576 - sparse_categorical_accuracy: 0.8339 - val_loss: 0.4840 - val_sparse_categorical_accuracy: 0.8385 - learning_rate: 1.2880e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 12s/step - loss: 0.3864 - sparse_categorical_accuracy: 0.8603 - val_loss: 0.4728 - val_sparse_categorical_accuracy: 0.8412 - learning_rate: 8.9200e-05\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 12s/step - loss: 0.3221 - sparse_categorical_accuracy: 0.8853 - val_loss: 0.4442 - val_sparse_categorical_accuracy: 0.8529 - learning_rate: 4.9600e-05\n",
      "Restoring model weights from the end of the best epoch: 25.\n"
     ]
    }
   ],
   "source": [
    "cb = [EarlyStopping(patience=15, monitor='val_loss', mode='auto' ,restore_best_weights=True,min_delta = 0.01,verbose = True)\n",
    "     ,LearningRateScheduler(schedule=schedule)]\n",
    "\n",
    "#WRN.fit(X_train, y_train, validation_data = (X_test, y_test), callbacks = cb ,verbose = True, epochs = 200 , batch_size= 64 )\n",
    "\n",
    "WRN.fit(X_train, y_train, validation_data = (X_test, y_test), callbacks = cb ,verbose = True, epochs = 25 , batch_size= 400 )\n",
    "\n",
    "WRN.save('saving/cifar10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f54ba8",
   "metadata": {},
   "source": [
    "# Sanity Check: evaluate the accuracy for one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3abd26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:54:41.086745Z",
     "iopub.status.busy": "2024-09-24T05:54:41.086386Z",
     "iopub.status.idle": "2024-09-24T05:54:41.434409Z",
     "shell.execute_reply": "2024-09-24T05:54:41.433609Z"
    },
    "papermill": {
     "duration": 0.616408,
     "end_time": "2024-09-24T05:54:41.436695",
     "exception": false,
     "start_time": "2024-09-24T05:54:40.820287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.batch(400).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0becf69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:54:41.996432Z",
     "iopub.status.busy": "2024-09-24T05:54:41.995442Z",
     "iopub.status.idle": "2024-09-24T05:54:47.505181Z",
     "shell.execute_reply": "2024-09-24T05:54:47.504257Z"
    },
    "papermill": {
     "duration": 5.787489,
     "end_time": "2024-09-24T05:54:47.507240",
     "exception": false,
     "start_time": "2024-09-24T05:54:41.719751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.8569 - sparse_categorical_accuracy: 0.4799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8256205320358276, 0.4975000023841858]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(test_dataset))\n",
    "images = tf.cast(images, tf.float32)\n",
    "labels = tf.squeeze(labels)\n",
    "labels = tf.cast(labels,tf.int32)\n",
    "adv = projected_gradient_descent(WRN,images,4,4/20,20,np.inf,y=labels)\n",
    "WRN.evaluate(adv,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d8cae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:54:48.040411Z",
     "iopub.status.busy": "2024-09-24T05:54:48.039668Z",
     "iopub.status.idle": "2024-09-24T05:54:50.092665Z",
     "shell.execute_reply": "2024-09-24T05:54:50.091804Z"
    },
    "papermill": {
     "duration": 2.321146,
     "end_time": "2024-09-24T05:54:50.094651",
     "exception": false,
     "start_time": "2024-09-24T05:54:47.773505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 11.1184 - sparse_categorical_accuracy: 0.0191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.969334602355957, 0.014999999664723873]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv = projected_gradient_descent(WRN,images,16,16/20,20,np.inf,y=labels)\n",
    "WRN.evaluate(adv,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ba7676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:54:50.634908Z",
     "iopub.status.busy": "2024-09-24T05:54:50.634543Z",
     "iopub.status.idle": "2024-09-24T05:54:50.647291Z",
     "shell.execute_reply": "2024-09-24T05:54:50.646526Z"
    },
    "papermill": {
     "duration": 0.284597,
     "end_time": "2024-09-24T05:54:50.649126",
     "exception": false,
     "start_time": "2024-09-24T05:54:50.364529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def IG(model, images, labels, steps = 15):\n",
    "    # interpolated intensities\n",
    "    alphas = tf.linspace(0.0,1.0,steps+1)\n",
    "    alphas_x = alphas[:,tf.newaxis, tf.newaxis, tf.newaxis,tf.newaxis]\n",
    "    alphas_x = tf.reshape(alphas_x,(1,alphas.shape[0],1,1,1))\n",
    "\n",
    "    # standardize input\n",
    "    images = tf.cast(images,'float32')\n",
    "\n",
    "    # calculate interpolated images\n",
    "    delta = tf.expand_dims(images,1)\n",
    "    interpolated = delta * alphas_x\n",
    "    # calculate gradient for each image\n",
    "    grads = tf.TensorArray(tf.float32,400)\n",
    "    i = 0\n",
    "    for inter in interpolated:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(inter)\n",
    "            probs = model(inter)[:,labels[0]]\n",
    "        grads = grads.write(i,tape.gradient(probs,inter))\n",
    "        \n",
    "        i+= 1\n",
    "\n",
    "    grads = grads.stack()\n",
    "\n",
    "    # aproximate integration using remain trapoziod\n",
    "    grads = (grads[:,:-1] + grads[:,1:]) / tf.constant(2.0)\n",
    "    avg_gradients = tf.math.reduce_mean(grads, axis=1)\n",
    "\n",
    "    integrated_gradient = images * avg_gradients\n",
    "\n",
    "    return integrated_gradient\n",
    "\n",
    "@tf.function\n",
    "def MIG(model, images, labels, epsilon = 16, iterations = 20):\n",
    "    g_t = tf.zeros_like(images)\n",
    "    x_t = images\n",
    "    eps_step = tf.constant(epsilon/iterations)\n",
    "    for i in tf.range(iterations):\n",
    "        # steps = 20 as research\n",
    "        #labels = tf.argmax(model(x_t) , -1)\n",
    "        delta_t = IG(model,x_t,labels) \n",
    "        g_t = g_t + (delta_t/tf.norm(delta_t,1))\n",
    "        x_h = x_t - eps_step * tf.sign(g_t)\n",
    "        x_t = tf.clip_by_value(x_h,x_h-epsilon,x_h+epsilon)\n",
    "    return tf.clip_by_value(x_t,0,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7427081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:54:51.184582Z",
     "iopub.status.busy": "2024-09-24T05:54:51.184221Z",
     "iopub.status.idle": "2024-09-24T05:55:50.678905Z",
     "shell.execute_reply": "2024-09-24T05:55:50.677981Z"
    },
    "papermill": {
     "duration": 59.923551,
     "end_time": "2024-09-24T05:55:50.839364",
     "exception": false,
     "start_time": "2024-09-24T05:54:50.915813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1070 - sparse_categorical_accuracy: 0.7879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0134222507476807, 0.8050000071525574]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_mig = MIG(WRN, images, labels, 16)\n",
    "WRN.evaluate(adv_mig,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccdde8f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:55:51.370785Z",
     "iopub.status.busy": "2024-09-24T05:55:51.370417Z",
     "iopub.status.idle": "2024-09-24T05:56:48.454095Z",
     "shell.execute_reply": "2024-09-24T05:56:48.453174Z"
    },
    "papermill": {
     "duration": 57.516944,
     "end_time": "2024-09-24T05:56:48.622866",
     "exception": false,
     "start_time": "2024-09-24T05:55:51.105922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5169 - sparse_categorical_accuracy: 0.8290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46495750546455383, 0.8424999713897705]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_mig = MIG(WRN, images, labels, 4)\n",
    "WRN.evaluate(adv_mig,labels)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38597.836781,
   "end_time": "2024-09-24T05:56:52.459440",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-23T19:13:34.622659",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
